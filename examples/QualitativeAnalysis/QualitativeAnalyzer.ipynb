{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/ahell/Documents/Python Projects/AIToolkit')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from ai_toolkit import AIModel, PromptBuilder, FileReader, FileWriter, AIProcess, Function, APIRequest, AITool\n",
    "from ai_toolkit.operations import ExtractKey, ConvertToJSON, Passthrough, Calculator\n",
    "from IPython.display import display, Markdown, HTML, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the environment variables\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-3.5-turbo',\n",
       " 'gpt-4',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'claude-1',\n",
       " 'claude-1-100k',\n",
       " 'claude-instant-1',\n",
       " 'claude-instant-1-100k',\n",
       " 'respell-gpt-4-wrapper']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIModel.ALL_MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_survey_id = 'adf4f406-757c-4e7d-b881-add3de4bbaf4'\n",
    "client_name = 'Marcfirst'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comments Request (APIRequest)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_url = f\"https://dev-api.insite.ledgestone.com/api/results/comments/{client_survey_id}/open_ended\"\n",
    "request_method = \"GET\"\n",
    "request_headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['BEARER_TOKEN']}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "comments_request = APIRequest(\"Comments Request\").set_input(\n",
    "    url=request_url, method=request_method, headers=request_headers)\n",
    "comments_request.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'comment': 'I am happy to have the opportunity to work at Marcfirst. ', 'nps_category': 'promoter', 'comment_number': 1, 'prompt_response_id': '019a6a43-09d2-4452-ac87-bb569e91f5dc'}, {'comment': 'Seems like this is started to be a corporation instead of a non-profit.', 'nps_category': 'detractor', 'comment_number': 2, 'prompt_response_id': '04f38390-8d79-427e-933e-4cfd41ad9a1c'}, {'comment': 'Marcfirst has been wonderful, and I look forward to growing with as we continue expanding and helping as many individuals as possible.', 'nps_category': 'promoter', 'comment_number': 3, 'prompt_response_id': '1ca2239e-359e-429c-b226-fc9845a94d00'}, {'comment': 'i think this company totally fails to recognize the accomplishments and acheivements of personnel that worked hard to get them to where they are today. They see workers that have had a long tenure with them as expendable and often frind a way to let them go, expecially if they are not enthusiastic with new ways of doing things or changes in the organization the employee sees as detrimental. They really limit yiour voice.', 'nps_category': 'detractor', 'comment_number': 4, 'prompt_response_id': '1d4af725-b7ee-4565-a8d8-9cb24bbdec37'}, {'comment': \"I have goals to work toward expanding and growing this company. I do not allow emotions to effect my work quality or prductivity. I am not one to want to shine a light on myself but unless I bring my productivity to someone's attention or my supervisor's attention, it goes unnoticed. I am in a position where I would like a professional mentor in how to build more professional skills but to also be more emotionally available to others and to become more empathetic while maintaining a professional view on how to grow this organization.\", 'nps_category': 'passive', 'comment_number': 5, 'prompt_response_id': '1f78bf5f-b2d8-41a8-854d-0d549a2542f3'}, {'comment': '-I see so many people over exhausting themselves by working insane amounts of hours and after talking to them, they feel obligated to or \"if they don\\'t, no one else will\". In this field, so many people will care too much for others and providing the help where they don\\'t recognize their own capacity. While this is one of our core values, I don\\'t think it is being focused on enough to recognize it from others or promoting any kind of healthy boundaries from work/home life. Almost everyone I know personally, takes work home after work hours or sacrifices a large extent of their personal life to complete responsibilities or do more that often isn\\'t recognized as unhealthy work balance. \\n-As a business perspective, productivity and numbers and profit is so important to plan for, and being clear that is not the point I want to make. In the last few years, documentation and reporting systems and hard pressure on numbers seems to be taking over the goals and expectations of staff. It appears there is more focus on finding more ways to add billable services and provide extensive documentation for staff that is taking away from the time a person should be directly supported. It doesn\\'t feel like we are adding meaningful support after looking at the effort and time it takes to prove it on paper with the current expectations. This also doesn\\'t help with being short staffed, where staff already don\\'t have enough time or support to give meaningful services outside of documentation time. I wish there was a more efficient solution and better support for the two very important things to happen at the same time- meaningful services provided AND quality content/efficient time to document it. ', 'nps_category': 'detractor', 'comment_number': 6, 'prompt_response_id': '2063b863-5e1b-471d-bad0-801421fe86ac'}, {'comment': \"I wish this company valued it's employees. Interpret that however you wish. It's actually easy to understand if you wanted to try. A 50 cent raise was a slap in the face to all your staff.\", 'nps_category': 'detractor', 'comment_number': 7, 'prompt_response_id': '2d4b6f92-c116-4600-a6fb-3a77603f490f'}, {'comment': 'Macfirst is amazing and in theory I love the core values and the close team I and direct supervisor I work with daily. As a whole there is a lot of talk about the concerns of pay, culture, feeling secure in job, overworked/understaffed (burnout/poor understanding of roles), living out the core values each day intended by the company. ', 'nps_category': 'detractor', 'comment_number': 8, 'prompt_response_id': '386b044a-07be-4fc1-bf9b-eb0efc7dc5a6'}, {'comment': 'I love working here', 'nps_category': 'promoter', 'comment_number': 9, 'prompt_response_id': '39f5f7d3-8fdc-433f-ad02-65de9748aab4'}, {'comment': 'this might be a reach but i think it would be helpful if each house has more than 1 person on night shift. not that i cant do it alone but i always think more is better than 1', 'nps_category': 'promoter', 'comment_number': 10, 'prompt_response_id': '425d47cb-6236-4f6a-bfd4-5ea55035fb2a'}, {'comment': \"The only thing I would like to add is do a job that you enjoy then you won't look at it as a job. I enjoy my work 150%!!\", 'nps_category': 'passive', 'comment_number': 11, 'prompt_response_id': '4cc9168f-7396-470f-bfba-fae5162340a3'}, {'comment': 'Feel like this organization cares more about the Peds program than anything else!!  ', 'nps_category': 'detractor', 'comment_number': 12, 'prompt_response_id': '5bc67895-56b1-49bd-a81c-c7885a4efeae'}, {'comment': \"It is a very good organization, have a great number of quality employee's, pay and benefits have improved immensely over time, and I have had the opportunity to grow professionally while being able to make an impact on people's lives on a daily basis.\", 'nps_category': 'passive', 'comment_number': 13, 'prompt_response_id': '5c8d3801-6c1d-4e7f-9eff-53f329a13ed1'}, {'comment': 'Overall this organization feels welcoming, and the work we do feels important. ', 'nps_category': 'promoter', 'comment_number': 14, 'prompt_response_id': '5f968e4b-3157-4a3e-9458-e2b9d0f97c25'}, {'comment': 'Iâ€™m pleased with our benefits package, and I feel honored to work with my coworkers.', 'nps_category': 'passive', 'comment_number': 15, 'prompt_response_id': '6a736024-5b82-493e-82f1-82ebe65b4fcd'}, {'comment': 'I feel like my supervisor is supportive and listens to me, but I often feel guilty asking questions or speaking my mind due to management being overwhelmed. I feel that my concerns are minimized and often not addressed or followed up on due to there being too much going on for my supervisor. ', 'nps_category': 'detractor', 'comment_number': 16, 'prompt_response_id': '6abc2a58-6b25-4f66-bee5-bc44e46ec4b4'}, {'comment': 'I don\\'t know that I will be completing anymore employee surveys after this one, as nothing seems to come of them and the information gained just gets used to placate. \\nI would also like to see a bit more professionalism and humility out of our CEO. The constant joking around, posturing, and swearing just makes us look bad. He\\'s not a bad guy but he just doesn\\'t present well and can be pretty tone-deaf at times. He can also be a bit of a bully at times. Also, there is some sort of weird clique involving HR and leadership to where employees don\\'t feel comfortable talking to HR about issues, which is unfortunate because that\\'s why we have an HR in the first place. \\n\\nI don\\'t know how much longer I will stick around. Marcfirst, or whatever it is rebranded to, will do just fine without me. I will miss the individuals we support however. A common sentiment among direct care staff is \"I love my job and the work I do, I just don\\'t love the company I do it for.\"', 'nps_category': 'detractor', 'comment_number': 17, 'prompt_response_id': '6abda611-9759-4f40-b604-3d0cff310b09'}, {'comment': 'Marcfirst used to be the \"go-to\" agency for best practice. I used to be very proud to work here. Now I wonder if the entire branch I work with with be eliminated altogether. If Christy was forced out, will I be next? Will it be a co-worker? It makes me sad and certainly takes the focus off of the families we serve. ', 'nps_category': 'detractor', 'comment_number': 18, 'prompt_response_id': '757dcfc3-9e9f-44f2-87c2-0ba855da5c58'}, {'comment': 'I love my job and the people I have the opportunity to support, but recently have felt forgotten or made to feel unnecessary. I really like this job and dont want to leave but it is hard when lack of communication makes you feel unwanted.', 'nps_category': 'passive', 'comment_number': 19, 'prompt_response_id': '758c8df6-f5b7-4b58-b716-834c8ed1565e'}, {'comment': \"There are many things that Marcfirst is doing right. Its vision is exciting and compelling and has garnered much community support. Leadership has been making efforts to highlight employee achievements and the monthly meetings are a great effort to build community within the whole organization. Individual staff who work with clients on a regular basis are amazing, committed, and talented. \\n  However, other staff may feel underappreciated and unseen in their behind-the-scenes roles which don't directly impact clients. Some staff's talents and gifts may be untapped that could provide a positive momentum in moving the company vision forward. Consider: how could Marcfirst build an atmosphere and culture where employees are not pigeon-holed into current roles, but were encouraged to explore and grow to meet the changing needs of the organization?\", 'nps_category': 'detractor', 'comment_number': 20, 'prompt_response_id': '763edd98-b767-4a78-9867-d9f503046c11'}, {'comment': 'Negatory', 'nps_category': 'passive', 'comment_number': 21, 'prompt_response_id': '80772e73-05a9-4769-9c79-db0c368753a4'}, {'comment': 'If the wages can be increased, especially for the hourly paid staff and add more to benefits.', 'nps_category': 'promoter', 'comment_number': 22, 'prompt_response_id': '93a6d088-235e-4798-be44-245a78843628'}, {'comment': 'Those who have stuck around with a company who has had a rocky past should be valued and appreciated. Sadly a lot of times money is involved with that. Or even getting the same benefits as others in similar rolls in the company. ', 'nps_category': 'detractor', 'comment_number': 23, 'prompt_response_id': '98c579a0-c51b-4aca-8635-cfa1ac4542d7'}, {'comment': \"Yes, the 50-cent raise is nice but with the cost of living and everything go up in price it would be nice to be making some more money.  Yes, it is nice that you gave us the money for ort PHMP but it would have been nice to get a little of that money in our paycheck as well. OR stop spending on the money on food for the quarterly Marcfirst hours and boarding meeting and all the money you spent on the tv's for all the rooms is a little crazy to.  that money could be going to your hard-working employees, so they gave have a decent living. \", 'nps_category': 'promoter', 'comment_number': 24, 'prompt_response_id': 'b03da1c5-18c5-432f-99cf-b1cbd4221b68'}, {'comment': 'I feel leaderships is completely out of touch with the people who actually do the job on the frontline, and it is getting worse.', 'nps_category': 'detractor', 'comment_number': 25, 'prompt_response_id': 'b2931815-c0aa-48d7-89e8-c24af338aade'}, {'comment': 'It feels ever since we made the move into the new building it feels there are a few in administration who do not know anything about those of us who are the workers, the engineers who are making sure the train is well-oiled, running smoothly, and on time.  They have no idea or clue what is being done daily, feeling we are not important. There are times we are going nonstop and trying to get everything that needs to get done for our individuals who are an important part of our jobs and agency. There are days when it feels like you are treading water to the point of exhaustion or drowning. \\nKnowing no life preserver will be thrown and you are on your own. We all have to work together to make this train work and run smoothly. Otherwise, this train engine will freeze up and stop running. \\n\\ndrowning. Knowing no life preserver will be thrown and you are on your own and hoping you will survive. We are hardly, ever asked what are we needing or if there is assistance needed. It is a daily survival between working, pay, and benefits. ', 'nps_category': 'detractor', 'comment_number': 26, 'prompt_response_id': 'b615757a-0035-4d1e-89c3-82ab2f60bdfe'}, {'comment': 'Love Marcfirst! \\n', 'nps_category': 'promoter', 'comment_number': 27, 'prompt_response_id': 'ce4ec89c-1e05-40cb-b5e9-a418e60e492b'}, {'comment': 'Make sure DSPs are part of decision making in the organization. Using their first experience would make programs more successful.', 'nps_category': 'passive', 'comment_number': 28, 'prompt_response_id': 'd23750c5-00f0-40cc-9848-4597f48d4494'}, {'comment': 'Overall I love Marcfirst and really enjoy working here.', 'nps_category': 'promoter', 'comment_number': 29, 'prompt_response_id': 'd34e88eb-f881-4296-b279-4c2576526912'}, {'comment': 'I appreciate the autonomy Marcfirst gives to each of their employees to define their own process of how to do a job based on our differences and various ideas. ', 'nps_category': 'promoter', 'comment_number': 30, 'prompt_response_id': 'd528f103-d29a-458e-bf18-5a8ee78ec253'}, {'comment': 'I believe employees need a better pay and better communication.  ', 'nps_category': 'promoter', 'comment_number': 31, 'prompt_response_id': 'd7e49ecb-6681-4ebd-ab2c-92a40ce5b2d7'}, {'comment': 'Marcfirst is by far the greatest/best nonprofit I have ever worked for in my life. I\\'m constantly amazed that I have the privilege to work here. I feel respected and part of a larger mission to help others. I feel heard by my supervisor and by leadership and that my thoughts and perspectives have merit and are taken seriously. I appreciate the business outlook taken to ensure we can maintain and grow programs, salaries, etc. Previous places I have worked did not have that business acumen and certainly did not take a \"staff first\" perspective. As a consequence, those other organizations struggled with staff and workplace culture as well as with finance basics to keep things operational. I feel secure working at Marcfirst and don\\'t feel like I\\'m \"working.\" I feel like I\\'m engaged in a larger project than something to just pay my bills. Everyone has bills to pay, but it\\'s great to be able to pay those bills while doing something that generates meaning and pride. ', 'nps_category': 'promoter', 'comment_number': 32, 'prompt_response_id': 'd8a9f4a1-0a78-4a22-8f2a-cd4f5384afc9'}, {'comment': 'I suggest that leadership, including the CEO, take the initiative to engage with our clients and visit our Adult CILA homes unannounced to ensure that any promotional efforts accurately represent the services and care we provide in our various programs and locations.\\nRecognizing our adult clients as \"MarcFirst Allstars\" would be a meaningful way to honor their contributions and showcase the diverse range of individuals we serve.\\n', 'nps_category': 'detractor', 'comment_number': 33, 'prompt_response_id': 'dd886968-003b-4e57-8f29-a3aba2fb2a59'}, {'comment': \"As a salaried employee, it is difficult to track my hours each week and I often feel that I am working over 40 hours/week to make deadlines, but I often don't take the time to track since there is no efficient way I have found to do so. Working with employees, even when we have flexible schedules, to make sure that we can track time spent and manage our workloads to fit the expected 40 hours/week would be helpful. \", 'nps_category': 'promoter', 'comment_number': 34, 'prompt_response_id': 'e3265b84-81b9-4ac6-9098-ca29a1f68fa4'}, {'comment': \"I feel like some of the things we are ask to do are above what i should be doing and i don't feel like some things are not delt with properly  \", 'nps_category': 'detractor', 'comment_number': 35, 'prompt_response_id': 'f47f1cb2-f882-4683-967c-87f1b7f6c8a9'}, {'comment': 'Their peer to peer is very hurtful to the staff that do all the work. We never get recognize   The CEO was cussing during a meeting. I would like to see the CEO show his core values he speaks of work 10 to twelve hours in a house and DT. Comforting someone changing bathing them. Break up a fight. Cook laundry clean. Take the individuals on outings. Work 8 to 12 hours without lunch or dinner. Two many frontline people that spend time in meetings. ', 'nps_category': 'detractor', 'comment_number': 36, 'prompt_response_id': 'feaf040a-2702-47c0-a65f-ff21164a4c54'}]\n"
     ]
    }
   ],
   "source": [
    "comments_function = ExtractKey(\"Comments List Extractor\").set_input(\n",
    "    input=comments_request, key_name=\"comments\")\n",
    "comments_function.process()\n",
    "comments_list = comments_function.get_output()\n",
    "print(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension Analyzer (AIProcess)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from typing import Any\n",
    "\n",
    "# class DimensionAnalyzerOutputFunction(CustomCodeBlock):\n",
    "#     def code(self):\n",
    "#         analysis = self.get_input(\"analysis\")\n",
    "\n",
    "# extract_comment = AITool().set_input(object=\"Function\"...)\n",
    "# dimension_prompt = AITool().set_input(object=\"PromptBuilder\"...)\n",
    "\n",
    "# extract_comment = ExtractComment(\"Name\").set_input(name_of_input=\"comments_list\", key_name=\"comment\")\n",
    "# dimension_analyzer_json = ConvertToJSON(\"Name\").set_input(name_of_input=\"dimension_analyzer_llm\")\n",
    "\n",
    "comment_dict_input = Passthrough(\"Comment Dict Input\").set_input(\n",
    "    name_of_input=\"comment_dict\")\n",
    "\n",
    "extract_comment = ExtractKey(\"Extract Comment\").set_input(\n",
    "    input=comment_dict_input, key_name=\"comment\")\n",
    "\n",
    "extract_comment_num = ExtractKey(\"Extract Comment Number\").set_input(\n",
    "    input=comment_dict_input, key_name=\"comment_number\")\n",
    "\n",
    "extract_prompt_response_id = ExtractKey(\"Extract Prompt Response ID\").set_input(\n",
    "    input=comment_dict_input, key_name=\"prompt_response_id\")\n",
    "\n",
    "dimension_prompt_file = FileReader(\"Dimension Analyzer File\").set_input(\n",
    "    file_path=\"dimension_prompt.txt\")\n",
    "\n",
    "dimension_prompt = PromptBuilder(\"Dimension Analyzer Prompt\").set_input(\n",
    "    template=dimension_prompt_file, comment=extract_comment)\n",
    "\n",
    "dimension_analyzer_llm = AIModel(\"Dimension Analyzer LLM\").set_input(\n",
    "    model_name=\"respell-gpt-4-wrapper\", prompt=dimension_prompt)\n",
    "\n",
    "dimension_analyzer_json = ConvertToJSON(\"Dimension Analyzer JSON\").set_input(\n",
    "    input=dimension_analyzer_llm)\n",
    "\n",
    "convert_support_and_regognition_to_value_function = \"\"\"\n",
    "    analysis = get_input(\"analysis\")\n",
    "    if 'Support & Recognition' in analysis:\n",
    "        analysis['Value'] = analysis.pop('Support & Recognition')\n",
    "    return analysis\n",
    "\"\"\"\n",
    "\n",
    "dimension_analyzer_output_function = \"\"\"\n",
    "    comment_number = get_input(\"comment_number\")\n",
    "    comment = get_input(\"comment\")\n",
    "    prompt_response_id = get_input(\"prompt_response_id\")\n",
    "    analysis = get_input(\"analysis\")\n",
    "    output = list()\n",
    "    for dimension, anal in analysis.items():\n",
    "        output.append({\n",
    "            \"comment_number\": comment_number,\n",
    "            \"comment\": comment,\n",
    "            \"prompt_response_id\": prompt_response_id,\n",
    "            \"dimension\": dimension,\n",
    "            \"analysis\": anal[\"analysis\"],\n",
    "            \"sentiment\": anal[\"sentiment\"]\n",
    "            })\n",
    "\n",
    "    return output\n",
    "\"\"\"\n",
    "\n",
    "convert_support_and_recognition_to_value = Function(\"Convert Support & Recognition to Value\").set_input(\n",
    "    function=convert_support_and_regognition_to_value_function, analysis=dimension_analyzer_json)\n",
    "\n",
    "dimension_analyzer_output = Function(\"Dimension Analyzer Output\").set_input(\n",
    "    function=dimension_analyzer_output_function, \n",
    "    comment_number=extract_comment_num, \n",
    "    comment=extract_comment,\n",
    "    prompt_response_id=extract_prompt_response_id, \n",
    "    analysis=convert_support_and_recognition_to_value)\n",
    "\n",
    "dimension_analyzer = AIProcess(\"Dimension Analyzer\")\n",
    "dimension_analyzer.expose_input(\"comment_dict\", comment_dict_input)\n",
    "dimension_analyzer.expose_output(dimension_analyzer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing comment 36 of 36\n",
      "Processing Comment Dict Input (Passthrough)\n",
      "Processing Extract Comment (ExtractKey)\n",
      "Processing Extract Comment Number (ExtractKey)\n",
      "Processing Extract Prompt Response ID (ExtractKey)\n",
      "Processing Dimension Analyzer File (FileReader)\n",
      "Processing Dimension Analyzer Prompt (PromptBuilder)\n",
      "Processing Dimension Analyzer LLM (AIModel)\n",
      "Processing Dimension Analyzer JSON (ConvertToJSON)\n",
      "Processing Convert Support & Recognition to Value (Function)\n",
      "Processing Dimension Analyzer Output (Function)\n"
     ]
    }
   ],
   "source": [
    "output = list()\n",
    "for i in range(len(comments_list)):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Processing comment {i+1} of {len(comments_list)}\")\n",
    "    dimension_analyzer.set_input(comment_dict=comments_list[i])\n",
    "    dimension_analyzer.process()\n",
    "    output.extend(dimension_analyzer.get_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File successfully written'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension_results_json = FileWriter(\"Save Dimension Analysis JSON\").set_input(file_path=f\"Clients/{client_name}/dimensions_json.json\", data=output)\n",
    "dimension_results_json.process()\n",
    "dimension_results_json.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "Skipping Not Applicable\n",
      "Skipping Not Applicable\n",
      "Skipping Not Applicable\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "dimensions_to_analyze = [\n",
    "    \"Accomplishment\",\n",
    "    \"Alignment\",\n",
    "    \"Compensation & Benefits\",\n",
    "    \"Connection\",\n",
    "    \"Diversity\",\n",
    "    \"Purpose\",\n",
    "    \"Security\",\n",
    "    \"Value\",\n",
    "    \"Work Environment\",\n",
    "    \"Workload & Stress\"\n",
    "]\n",
    "print(len(output))\n",
    "dimension_ouput_for_driver_analysis = list()\n",
    "for comment_analysis in output:\n",
    "    dimension = comment_analysis[\"dimension\"]\n",
    "    if dimension in dimensions_to_analyze:\n",
    "        dimension_ouput_for_driver_analysis.append(comment_analysis)\n",
    "    else:\n",
    "        print(f\"Skipping {dimension}\")\n",
    "\n",
    "print(len(dimension_ouput_for_driver_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Driver Analyzer (AIProcess)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_dict_input = Passthrough(\"Comment Dict Input\").set_input(\n",
    "    name_of_input=\"comment_dict\")\n",
    "\n",
    "extract_comment = ExtractKey(\"Extract Comment\").set_input(\n",
    "    input=comment_dict_input, key_name=\"comment\")\n",
    "\n",
    "extract_comment_num = ExtractKey(\"Extract Comment Number\").set_input(\n",
    "    input=comment_dict_input, key_name=\"comment_number\")\n",
    "\n",
    "extract_prompt_response_id = ExtractKey(\"Extract Prompt Response ID\").set_input(\n",
    "    input=comment_dict_input, key_name=\"prompt_response_id\")\n",
    "\n",
    "extract_dimension = ExtractKey(\"Extract Dimension\").set_input(\n",
    "    input=comment_dict_input, key_name=\"dimension\")\n",
    "\n",
    "extract_analysis = ExtractKey(\"Extract Analysis\").set_input(\n",
    "    input=comment_dict_input, key_name=\"analysis\")\n",
    "\n",
    "extract_sentiment = ExtractKey(\"Extract Sentiment\").set_input(\n",
    "    input=comment_dict_input, key_name=\"sentiment\")\n",
    "\n",
    "driver_prompt_file_name_function = \"\"\"\n",
    "    dimension = get_input(\"dimension\")\n",
    "    return f\"driver_prompt_{dimension.lower().replace(' ', '_').replace('&', 'and')}.txt\"\n",
    "\"\"\"\n",
    "\n",
    "driver_prompt_file_name = Function(\"Driver Prompt File Name\").set_input(\n",
    "    function=driver_prompt_file_name_function, dimension=extract_dimension)\n",
    "\n",
    "driver_prompt_file = FileReader(\"Driver Analyzer File\").set_input(\n",
    "    file_path=driver_prompt_file_name)\n",
    "\n",
    "driver_prompt = PromptBuilder(\"Driver Analyzer Prompt\").set_input(\n",
    "    template=driver_prompt_file, comment=extract_comment, value_analysis=extract_analysis)\n",
    "\n",
    "driver_analyzer_llm = AIModel(\"Driver Analyzer LLM\").set_input(\n",
    "    model_name=\"gpt-4\", prompt=driver_prompt)\n",
    "\n",
    "driver_analyzer_json = ConvertToJSON(\"Driver Analyzer JSON\").set_input(\n",
    "    input=driver_analyzer_llm)\n",
    "\n",
    "driver_analyzer_output_function = \"\"\"\n",
    "    comment_num = get_input(\"comment_number\")\n",
    "    comment = get_input(\"comment\")\n",
    "    prompt_response_id = get_input(\"prompt_response_id\")\n",
    "    dimension = get_input(\"dimension\")\n",
    "    analysis = get_input(\"analysis\")\n",
    "    sentiment = get_input(\"sentiment\")\n",
    "    takeaway = get_input(\"takeaway\")\n",
    "    output = list()\n",
    "    for driver, takeaway in takeaway.items():\n",
    "        output.append({\n",
    "            'prompt_response_id': prompt_response_id,\n",
    "            'comment_num': comment_num,\n",
    "            'dimension': dimension,\n",
    "            'sentiment': sentiment,\n",
    "            'comment': comment,\n",
    "            'analysis': analysis,\n",
    "            'driver': driver,\n",
    "            'takeaway': takeaway\n",
    "        })\n",
    "\n",
    "    return output\n",
    "\"\"\"\n",
    "\n",
    "driver_analyzer_output = Function(\"Driver Analyzer Output\").set_input(\n",
    "    function=driver_analyzer_output_function, \n",
    "    comment_number=extract_comment_num,\n",
    "    comment=extract_comment,\n",
    "    prompt_response_id=extract_prompt_response_id,\n",
    "    dimension=extract_dimension,\n",
    "    analysis=extract_analysis,\n",
    "    sentiment=extract_sentiment,\n",
    "    takeaway=driver_analyzer_json)\n",
    "\n",
    "driver_analyzer = AIProcess(\"Driver Analyzer\")\n",
    "driver_analyzer.expose_input(\"comment_dict\", comment_dict_input)\n",
    "driver_analyzer.expose_output(driver_analyzer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing comment 12 of 78\n",
      "Processing Comment Dict Input (Passthrough)\n",
      "Processing Extract Comment (ExtractKey)\n",
      "Processing Extract Comment Number (ExtractKey)\n",
      "Processing Extract Prompt Response ID (ExtractKey)\n",
      "Processing Extract Dimension (ExtractKey)\n",
      "Processing Driver Prompt File Name (Function)\n",
      "Processing Driver Analyzer File (FileReader)\n",
      "Processing Extract Analysis (ExtractKey)\n",
      "Processing Extract Sentiment (ExtractKey)\n",
      "Processing Driver Analyzer Prompt (PromptBuilder)\n",
      "Processing Driver Analyzer LLM (AIModel)\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for 10KTPM-200RPM in organization org-1ra0eeBjtT69TLEagEMEAA9n on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing comment \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(dimension_ouput_for_driver_analysis)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m driver_analyzer\u001b[39m.\u001b[39mset_input(comment_dict\u001b[39m=\u001b[39mdimension_ouput_for_driver_analysis[i])\n\u001b[0;32m----> 6\u001b[0m driver_analyzer\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m      7\u001b[0m driver_output\u001b[39m.\u001b[39mextend(driver_analyzer\u001b[39m.\u001b[39mget_output())\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/ai_toolkit/ai_tool.py:28\u001b[0m, in \u001b[0;36mAITool.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mraise\u001b[39;00m AINonRetryableError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot process \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m because not all inputs are present.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m                              Required inputs: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequired_input\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mDynamic inputs: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_input\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdependents_received_output \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[0;32m---> 28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/ai_toolkit/ai_process.py:30\u001b[0m, in \u001b[0;36mAIProcess._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mif\u001b[39;00m ai_tool\u001b[39m.\u001b[39mcan_process():\n\u001b[1;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{\u001b[39;00mai_tool\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     ai_tool\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m     31\u001b[0m     processed_tools\u001b[39m.\u001b[39mappend(ai_tool)\n\u001b[1;32m     32\u001b[0m     still_processing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/ai_toolkit/ai_tool.py:28\u001b[0m, in \u001b[0;36mAITool.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mraise\u001b[39;00m AINonRetryableError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot process \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m because not all inputs are present.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m                              Required inputs: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequired_input\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mDynamic inputs: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamic_input\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdependents_received_output \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[0;32m---> 28\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n\u001b[1;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/ai_toolkit/tools/ai_model.py:45\u001b[0m, in \u001b[0;36mAIModel._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_message_formatting(messages)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mOPENAI_MODEL_NAMES:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_completion_openai(model_name, messages, max_tokens, temperature)\n\u001b[1;32m     46\u001b[0m \u001b[39melif\u001b[39;00m model_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mANTHROPIC_MODEL_NAMES:\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_completion_anthropic(model_name, messages, max_tokens)\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/ai_toolkit/tools/ai_model.py:102\u001b[0m, in \u001b[0;36mAIModel._get_completion_openai\u001b[0;34m(self, model_name, messages, max_tokens, temperature)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_completion_openai\u001b[39m(\u001b[39mself\u001b[39m, model_name: \u001b[39mstr\u001b[39m, messages: List[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]], max_tokens: \u001b[39mint\u001b[39m, temperature: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 102\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m    103\u001b[0m         model\u001b[39m=\u001b[39;49mmodel_name,\n\u001b[1;32m    104\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m    105\u001b[0m         temperature\u001b[39m=\u001b[39;49mtemperature, \u001b[39m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[1;32m    106\u001b[0m         max_tokens\u001b[39m=\u001b[39;49mmax_tokens, \u001b[39m# this is the maximum number of tokens to generate\u001b[39;49;00m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/AIToolkitVenv/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/AIToolkitVenv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/AIToolkitVenv/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/AIToolkitVenv/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Python Projects/AIToolkit/AIToolkitVenv/lib/python3.10/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for 10KTPM-200RPM in organization org-1ra0eeBjtT69TLEagEMEAA9n on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues."
     ]
    }
   ],
   "source": [
    "driver_output = list()\n",
    "for i in range(len(dimension_ouput_for_driver_analysis)):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Processing comment {i+1} of {len(dimension_ouput_for_driver_analysis)}\")\n",
    "    driver_analyzer.set_input(comment_dict=dimension_ouput_for_driver_analysis[i])\n",
    "    driver_analyzer.process()\n",
    "    driver_output.extend(driver_analyzer.get_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Pride\": \"From this employee\\'s experience, the uncertainty and fear of job security is negatively affecting their pride in the organization; therefore, leaders need to address these concerns transparently and promptly because such uncertainties can divert focus from the core purpose of serving families.\"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Pride': \"From this employee's experience, the uncertainty and fear of job security is negatively affecting their pride in the organization; therefore, leaders need to address these concerns transparently and promptly because such uncertainties can divert focus from the core purpose of serving families.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "display(driver_analyzer_llm.get_output())\n",
    "\n",
    "data = '{\"Pride\": \"From this employee\\'s experience, the uncertainty and fear of job security is negatively affecting their pride in the organization; therefore, leaders need to address these concerns transparently and promptly because such uncertainties can divert focus from the core purpose of serving families.\"}'\n",
    "json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_results_json = FileWriter(\"Save Driver Analysis JSON\").set_input(file_path=f\"Clients/{client_name}/drivers_json.json\", data=driver_output)\n",
    "driver_results_json.process()\n",
    "driver_results_json.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_keys = ['Meaning', 'Pride', 'Significance', 'Supervisor', 'Organization', 'Appreciation', 'Team', 'Empowerment', 'Investment', 'Impact', 'Clarity', 'Advancement', 'Strategy', 'Vision', 'Mastery', 'Trust', 'Equity', 'Execution']\n",
    "extra_keep_keys = ['Compensation', 'Work Environment', 'Workload & Stress', 'Diversity']\n",
    "\n",
    "result_dict = {}\n",
    "for anal in driver_output:\n",
    "        if not (anal['driver'] in keep_keys or anal['driver'] in extra_keep_keys):\n",
    "            continue\n",
    "        dimension = row['Comment']['dimension']\n",
    "        comment = row['Comment']['comment']\n",
    "        analysis = row['Comment']['analysis']\n",
    "        comment_num = row['Comment']['comment_number']\n",
    "        takeaway = row['Takeaway']\n",
    "        for key, value in takeaway.items():\n",
    "            if key in result_dict:\n",
    "                result_dict[key].append(f'{comment_num} - {value}')\n",
    "            else:\n",
    "                result_dict[key] = [f'{comment_num} - {value}']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIToolkitVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
