{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/ahell/Documents/Python Projects/AIToolkit')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import ai_toolkit as ai\n",
    "from IPython.display import display, Markdown, HTML, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the environment variables\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.tools.LLM.ALL_MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_survey_id = 'adf4f406-757c-4e7d-b881-add3de4bbaf4'\n",
    "client_name = 'Marcfirst'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_url = f\"https://dev-api.insite.ledgestone.com/api/results/comments/{client_survey_id}/nps_justification\"\n",
    "request_method = \"GET\"\n",
    "request_headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['BEARER_TOKEN']}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "comments_request = ai.io.APIRequest(\"Comments Request\").set_input(\n",
    "    url=request_url, method=request_method, headers=request_headers)\n",
    "comments_request.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_function = ai.operations.ExtractKey(\"Comments List Extractor\").set_input(\n",
    "    input=comments_request, key_name=\"comments\")\n",
    "comments_function.process()\n",
    "comments_list = comments_function.get_output()\n",
    "print(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_dict_input = ai.operations.Passthrough(\"Comment Dict Input\").set_input(\n",
    "    name_of_input=\"comment_dict\")\n",
    "\n",
    "class CreateMetadata(ai.CustomCodeBlock):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.required_input = [\"comment_dict\"]\n",
    "\n",
    "    def code(self):\n",
    "        comment_dict = self.get_input(\"comment_dict\")\n",
    "        return {\n",
    "            \"client_survey_id\": client_survey_id,\n",
    "            \"source\": \"QualitativeAnalyzer.ipynb\",\n",
    "            \"function\": \"NPS Followup Analysis\",\n",
    "            \"prompt_response_id\": comment_dict[\"prompt_response_id\"],\n",
    "            \"comment_number\": str(comment_dict[\"comment_number\"])\n",
    "        }\n",
    "    \n",
    "create_metadata = CreateMetadata(\"Create Metadata\").set_input(\n",
    "    comment_dict=comment_dict_input)\n",
    "\n",
    "class CreateReplacements(ai.CustomCodeBlock):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.required_input = [\"comment_dict\"]\n",
    "\n",
    "    def code(self):\n",
    "        comment_dict = self.get_input(\"comment_dict\")\n",
    "        return {\n",
    "            \"comment\": comment_dict[\"comment\"]\n",
    "        }\n",
    "    \n",
    "replacements_for_llm = CreateReplacements(\"Create Replacements\").set_input(\n",
    "    comment_dict=comment_dict_input)\n",
    "\n",
    "dimension_analyzer_llm = ai.composed.LLMWithPromptRetrievalAndTracking(\"Dimension Analyzer LLM\").set_input(\n",
    "    template_name=\"Comment Dimension Analyzer\",\n",
    "    promptlayer_tags=[client_name],\n",
    "    replacements=replacements_for_llm,\n",
    "    model_name=\"gpt-4\",\n",
    "    metadata=create_metadata)\n",
    "\n",
    "dimension_analyzer_json = ai.operations.ConvertToJSON(\"Dimension Analyzer JSON\").set_input(\n",
    "    input=dimension_analyzer_llm)\n",
    "\n",
    "class ConvertSupportAndRecognitionToValue(ai.CustomCodeBlock):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.required_input = [\"analysis\"]\n",
    "\n",
    "    def code(self):\n",
    "        analysis = self.get_input(\"analysis\")\n",
    "        if 'Support & Recognition' in analysis:\n",
    "            analysis['Value'] = analysis.pop('Support & Recognition')\n",
    "        return analysis\n",
    "\n",
    "convert_support_and_regognition_to_value = ConvertSupportAndRecognitionToValue(\"Convert Support & Recognition to Value\").set_input(\n",
    "    analysis=dimension_analyzer_json)\n",
    "\n",
    "class DimensionAnalyzerOutput(ai.CustomCodeBlock):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.required_input = [\"comment_dict\", \"analysis\"]\n",
    "\n",
    "    def code(self):\n",
    "        comment_dict = self.get_input(\"comment_dict\")\n",
    "        analysis = self.get_input(\"analysis\")\n",
    "        output = list()\n",
    "        for dimension, anal in analysis.items():\n",
    "            output.append({\n",
    "                \"comment_number\": comment_dict[\"comment_number\"],\n",
    "                \"comment\": comment_dict[\"comment\"],\n",
    "                \"prompt_response_id\": comment_dict[\"prompt_response_id\"],\n",
    "                \"dimension\": dimension,\n",
    "                \"analysis\": anal[\"analysis\"],\n",
    "                \"sentiment\": anal[\"sentiment\"]\n",
    "                })\n",
    "\n",
    "        return output\n",
    "\n",
    "dimension_analyzer_output = DimensionAnalyzerOutput(\"Dimension Analyzer Output Function\").set_input(\n",
    "    comment_dict=comment_dict_input, analysis=convert_support_and_regognition_to_value)\n",
    "\n",
    "\n",
    "dimension_analyzer = ai.AIProcess(\"Dimension Analyzer\")\n",
    "dimension_analyzer.expose_input(\"comment_dict\", comment_dict_input)\n",
    "dimension_analyzer.expose_output(dimension_analyzer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for i in range(len(comments_list)):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Processing comment {i+1} of {len(comments_list)}\")\n",
    "    dimension_analyzer.set_input(comment_dict=comments_list[i])\n",
    "    dimension_analyzer.process()\n",
    "    output.extend(dimension_analyzer.get_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_analyzer.can_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_results_json = ai.io.FileWriter(\"Save Dimension Analysis JSON\").set_input(file_path=f\"Clients/{client_name}/dimensions_json.json\", data=output)\n",
    "dimension_results_json.process()\n",
    "dimension_results_json.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions_to_analyze = [\n",
    "    \"Accomplishment\",\n",
    "    \"Alignment\",\n",
    "    \"Compensation & Benefits\",\n",
    "    \"Connection\",\n",
    "    \"Diversity\",\n",
    "    \"Purpose\",\n",
    "    \"Security\",\n",
    "    \"Value\",\n",
    "    \"Work Environment\",\n",
    "    \"Workload & Stress\"\n",
    "]\n",
    "print(len(output))\n",
    "dimension_ouput_for_driver_analysis = list()\n",
    "for comment_analysis in output:\n",
    "    dimension = comment_analysis[\"dimension\"]\n",
    "    if dimension in dimensions_to_analyze:\n",
    "        dimension_ouput_for_driver_analysis.append(comment_analysis)\n",
    "    else:\n",
    "        print(f\"Skipping {dimension}\")\n",
    "\n",
    "print(len(dimension_ouput_for_driver_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_dict_input = ai.operations.Passthrough(\"Comment Dict Input\").set_input(\n",
    "    name_of_input=\"comment_dict\")\n",
    "\n",
    "extract_comment = ai.operations.ExtractKey(\"Extract Comment\").set_input(\n",
    "    input=comment_dict_input, key_name=\"comment\")\n",
    "\n",
    "extract_comment_num = ai.operations.ExtractKey(\"Extract Comment Number\").set_input(\n",
    "    input=comment_dict_input, key_name=\"comment_number\")\n",
    "\n",
    "extract_prompt_response_id = ai.operations.ExtractKey(\"Extract Prompt Response ID\").set_input(\n",
    "    input=comment_dict_input, key_name=\"prompt_response_id\")\n",
    "\n",
    "extract_dimension = ai.operations.ExtractKey(\"Extract Dimension\").set_input(\n",
    "    input=comment_dict_input, key_name=\"dimension\")\n",
    "\n",
    "extract_analysis = ai.operations.ExtractKey(\"Extract Analysis\").set_input(\n",
    "    input=comment_dict_input, key_name=\"analysis\")\n",
    "\n",
    "extract_sentiment = ai.operations.ExtractKey(\"Extract Sentiment\").set_input(\n",
    "    input=comment_dict_input, key_name=\"sentiment\")\n",
    "\n",
    "driver_prompt_file_name_function = \"\"\"\n",
    "    dimension = get_input(\"dimension\")\n",
    "    return f\"driver_prompt_{dimension.lower().replace(' ', '_').replace('&', 'and')}.txt\"\n",
    "\"\"\"\n",
    "\n",
    "driver_prompt_file_name = ai.tools.Function(\"Driver Prompt File Name\").set_input(\n",
    "    function=driver_prompt_file_name_function, dimension=extract_dimension)\n",
    "\n",
    "driver_prompt_file = ai.io.FileReader(\"Driver Analyzer File\").set_input(\n",
    "    file_path=driver_prompt_file_name)\n",
    "\n",
    "driver_prompt = ai.tools.PromptBuilder(\"Driver Analyzer Prompt\").set_input(\n",
    "    template=driver_prompt_file, comment=extract_comment, value_analysis=extract_analysis)\n",
    "\n",
    "driver_analyzer_llm = ai.tools.LLM(\"Driver Analyzer LLM\").set_input(\n",
    "    model_name=\"gpt-4\", prompt=driver_prompt)\n",
    "\n",
    "driver_analyzer_json = ai.operations.ConvertToJSON(\"Driver Analyzer JSON\").set_input(\n",
    "    input=driver_analyzer_llm)\n",
    "\n",
    "driver_analyzer_output_function = \"\"\"\n",
    "    comment_num = get_input(\"comment_number\")\n",
    "    comment = get_input(\"comment\")\n",
    "    prompt_response_id = get_input(\"prompt_response_id\")\n",
    "    dimension = get_input(\"dimension\")\n",
    "    analysis = get_input(\"analysis\")\n",
    "    sentiment = get_input(\"sentiment\")\n",
    "    takeaway = get_input(\"takeaway\")\n",
    "    output = list()\n",
    "    for driver, takeaway in takeaway.items():\n",
    "        output.append({\n",
    "            'prompt_response_id': prompt_response_id,\n",
    "            'comment_num': comment_num,\n",
    "            'dimension': dimension,\n",
    "            'sentiment': sentiment,\n",
    "            'comment': comment,\n",
    "            'analysis': analysis,\n",
    "            'driver': driver,\n",
    "            'takeaway': takeaway\n",
    "        })\n",
    "\n",
    "    return output\n",
    "\"\"\"\n",
    "\n",
    "driver_analyzer_output = ai.tools.Function(\"Driver Analyzer Output\").set_input(\n",
    "    function=driver_analyzer_output_function, \n",
    "    comment_number=extract_comment_num,\n",
    "    comment=extract_comment,\n",
    "    prompt_response_id=extract_prompt_response_id,\n",
    "    dimension=extract_dimension,\n",
    "    analysis=extract_analysis,\n",
    "    sentiment=extract_sentiment,\n",
    "    takeaway=driver_analyzer_json)\n",
    "\n",
    "driver_analyzer = ai.AIProcess(\"Driver Analyzer\")\n",
    "driver_analyzer.expose_input(\"comment_dict\", comment_dict_input)\n",
    "driver_analyzer.expose_output(driver_analyzer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_output = list()\n",
    "for i in range(len(dimension_ouput_for_driver_analysis)):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Processing comment {i+1} of {len(dimension_ouput_for_driver_analysis)}\")\n",
    "    driver_analyzer.set_input(comment_dict=dimension_ouput_for_driver_analysis[i])\n",
    "    driver_analyzer.process()\n",
    "    driver_output.extend(driver_analyzer.get_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "display(driver_analyzer_llm.get_output())\n",
    "\n",
    "data = '{\"Pride\": \"From this employee\\'s experience, the uncertainty and fear of job security is negatively affecting their pride in the organization; therefore, leaders need to address these concerns transparently and promptly because such uncertainties can divert focus from the core purpose of serving families.\"}'\n",
    "json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_results_json = ai.io.FileWriter(\"Save Driver Analysis JSON\").set_input(file_path=f\"Clients/{client_name}/drivers_json.json\", data=driver_output)\n",
    "driver_results_json.process()\n",
    "driver_results_json.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_keys = ['Meaning', 'Pride', 'Significance', 'Supervisor', 'Organization', 'Appreciation', 'Team', 'Empowerment', 'Investment', 'Impact', 'Clarity', 'Advancement', 'Strategy', 'Vision', 'Mastery', 'Trust', 'Equity', 'Execution']\n",
    "extra_keep_keys = ['Compensation', 'Work Environment', 'Workload & Stress', 'Diversity']\n",
    "\n",
    "result_dict = {}\n",
    "for anal in driver_output:\n",
    "        if not (anal['driver'] in keep_keys or anal['driver'] in extra_keep_keys):\n",
    "            continue\n",
    "        dimension = row['Comment']['dimension']\n",
    "        comment = row['Comment']['comment']\n",
    "        analysis = row['Comment']['analysis']\n",
    "        comment_num = row['Comment']['comment_number']\n",
    "        takeaway = row['Takeaway']\n",
    "        for key, value in takeaway.items():\n",
    "            if key in result_dict:\n",
    "                result_dict[key].append(f'{comment_num} - {value}')\n",
    "            else:\n",
    "                result_dict[key] = [f'{comment_num} - {value}']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIToolkitVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
